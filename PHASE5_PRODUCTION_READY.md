# ğŸš€ FutureOS Phase 5: Production Ready â€” ä¸Šçº¿å‰æœ€åå†²åˆº
# Phase 3 åŠŸèƒ½å…¨éƒ¨å®Œæˆï¼ŒPhase 4 æµ‹è¯•å…¨ç»¿ã€‚ç°åœ¨æŠŠäº§å“ä»"èƒ½è·‘"å˜æˆ"èƒ½ä¸Šçº¿"ã€‚

---

å…ˆé˜…è¯» docs/BLUEPRINT.md å’Œ docs/sessions/current.md å’Œ docs/sessions/test-report.md æ¢å¤ä¸Šä¸‹æ–‡ã€‚

æ‰€æœ‰åŠŸèƒ½å·²å®ç°å¹¶æµ‹è¯•é€šè¿‡(187åç«¯+78E2E+7å‰ç«¯=272æµ‹è¯•)ã€‚
ç°åœ¨åšä¸Šçº¿å‰æœ€åå†²åˆºï¼šçœŸå®æ•°æ®æºã€æ€§èƒ½ä¼˜åŒ–ã€å®‰å…¨åŠ å›ºã€SEOã€ç›‘æ§ã€UIæè‡´æ‰“ç£¨ã€‚

åŸåˆ™ï¼š
- ä¸åŠ æ–°åŠŸèƒ½ï¼Œåªæ‰“ç£¨å·²æœ‰åŠŸèƒ½
- æ¯æ”¹ä¸€å¤„è·‘ä¸€æ¬¡ç›¸å…³æµ‹è¯•ç¡®è®¤ä¸å›å½’
- è‡ªä¸»å†³ç­–ï¼Œå®Œæˆåæ±‡æŠ¥

---

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PART I: çœŸå®æ•°æ®æºæ¥å…¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## é˜¶æ®µ O: æ›¿æ¢Mockæ•°æ®ä¸ºçœŸå®æ•°æ®

ç°åœ¨Pipeline Stage 2 ç”¨çš„æ˜¯ç¡¬ç¼–ç Mockæ•°æ®ã€‚æ¥å…¥çœŸå®å…è´¹APIã€‚

### O1: ä¸–ç•Œé“¶è¡Œç»æµæ•°æ®
åˆ›å»º `api/app/services/data_providers/worldbank.py`:

```python
"""
ä¸–ç•Œé“¶è¡Œ Open Data API
https://api.worldbank.org/v2/
å…è´¹ï¼Œæ— éœ€API Key
"""
import httpx

BASE_URL = "https://api.worldbank.org/v2"

async def get_gdp(country_code: str = "MYS", years: int = 5) -> dict:
    """è·å–GDPæ•°æ®"""
    url = f"{BASE_URL}/country/{country_code}/indicator/NY.GDP.MKTP.CD"
    params = {"format": "json", "per_page": years, "date": f"2020:2025"}
    async with httpx.AsyncClient(timeout=15) as client:
        resp = await client.get(url, params=params)
        data = resp.json()
    # è§£æè¿”å› [{year, value, country}]
    return _parse_wb_response(data)

async def get_population(country_code: str = "MYS") -> dict:
    """è·å–äººå£æ•°æ®"""
    url = f"{BASE_URL}/country/{country_code}/indicator/SP.POP.TOTL"
    params = {"format": "json", "per_page": 5, "date": "2020:2025"}
    async with httpx.AsyncClient(timeout=15) as client:
        resp = await client.get(url, params=params)
        data = resp.json()
    return _parse_wb_response(data)

async def get_unemployment(country_code: str = "MYS") -> dict:
    """å¤±ä¸šç‡"""
    url = f"{BASE_URL}/country/{country_code}/indicator/SL.UEM.TOTL.ZS"
    params = {"format": "json", "per_page": 5, "date": "2020:2025"}
    async with httpx.AsyncClient(timeout=15) as client:
        resp = await client.get(url, params=params)
        data = resp.json()
    return _parse_wb_response(data)

async def get_inflation(country_code: str = "MYS") -> dict:
    """é€šèƒ€ç‡"""
    url = f"{BASE_URL}/country/{country_code}/indicator/FP.CPI.TOTL.ZG"
    params = {"format": "json", "per_page": 5, "date": "2020:2025"}
    async with httpx.AsyncClient(timeout=15) as client:
        resp = await client.get(url, params=params)
        data = resp.json()
    return _parse_wb_response(data)

def _parse_wb_response(data) -> list:
    """è§£æä¸–ç•Œé“¶è¡ŒAPIå“åº”"""
    if not data or len(data) < 2:
        return []
    return [
        {"year": item["date"], "value": item["value"], "country": item["country"]["value"]}
        for item in data[1] if item["value"] is not None
    ]
```

### O2: æ–°é—»/æƒ…æ„Ÿæ•°æ®
åˆ›å»º `api/app/services/data_providers/news.py`:

```python
"""
æ–°é—»æ•°æ® â€” ä½¿ç”¨å…è´¹çš„ NewsData.io æˆ– GNews API
å¦‚æœæ²¡æœ‰API Keyï¼Œç”¨LLMç”Ÿæˆæ¨¡æ‹Ÿæ–°é—»æ‘˜è¦
"""
import httpx
import os

NEWSDATA_API_KEY = os.environ.get("NEWSDATA_API_KEY", "")

async def get_news_sentiment(query: str, country: str = "my", count: int = 10) -> dict:
    """è·å–ç›¸å…³æ–°é—»å¹¶åˆ†ææƒ…æ„Ÿ"""
    articles = await _fetch_news(query, country, count)
    
    if not articles:
        # Fallback: ç”¨LLMç”Ÿæˆå½“å‰äº‹ä»¶æ‘˜è¦
        return await _llm_news_fallback(query)
    
    # ç”¨LLMåˆ†ææ–°é—»æƒ…æ„Ÿ
    from app.core.llm import call_llm_json
    sentiment = await call_llm_json("sentiment_analysis", [{
        "role": "user",
        "content": f"""Analyze the sentiment of these news headlines related to "{query}":
{chr(10).join([f'- {a["title"]}' for a in articles[:10]])}

Return JSON: {{
  "overall_sentiment": -1.0 to 1.0,
  "positive_themes": ["theme1", "theme2"],
  "negative_themes": ["theme1"],
  "key_events": ["event1", "event2"],
  "summary": "2-3 sentence summary"
}}"""
    }])
    
    return {
        "articles": articles[:5],
        "sentiment": sentiment,
        "source": "newsdata" if NEWSDATA_API_KEY else "llm_generated"
    }

async def _fetch_news(query: str, country: str, count: int) -> list:
    """ä»æ–°é—»APIè·å–æ–‡ç« """
    if not NEWSDATA_API_KEY:
        return []
    
    url = "https://newsdata.io/api/1/news"
    params = {
        "apikey": NEWSDATA_API_KEY,
        "q": query,
        "country": country,
        "language": "en,ms",
        "size": count
    }
    try:
        async with httpx.AsyncClient(timeout=10) as client:
            resp = await client.get(url, params=params)
            data = resp.json()
        return [{"title": a["title"], "source": a["source_id"], "date": a["pubDate"]} 
                for a in data.get("results", [])]
    except Exception:
        return []

async def _llm_news_fallback(query: str) -> dict:
    """æ— æ–°é—»APIæ—¶ç”¨LLMç”Ÿæˆä¸Šä¸‹æ–‡"""
    from app.core.llm import call_llm_json
    return await call_llm_json("data_gap_fill", [{
        "role": "user",
        "content": f"""Based on your knowledge, provide current context about: "{query}"

Return JSON: {{
  "articles": [],
  "sentiment": {{
    "overall_sentiment": 0.0,
    "positive_themes": [],
    "negative_themes": [],
    "key_events": [],
    "summary": "summary based on general knowledge"
  }},
  "source": "llm_knowledge"
}}"""
    }])
```

### O3: é©¬æ¥è¥¿äºšç‰¹å®šæ•°æ®
åˆ›å»º `api/app/services/data_providers/malaysia.py`:

```python
"""
é©¬æ¥è¥¿äºšç‰¹å®šæ•°æ® (é€‰ä¸¾/äººå£/ç»æµ)
æ¥æº: DOSM (Department of Statistics Malaysia) Open Data
https://open.dosm.gov.my/
"""

# ç¡¬ç¼–ç ä½†çœŸå®çš„é©¬æ¥è¥¿äºšæ•°æ® (æ¥è‡ªDOSM 2023å¹´ç»Ÿè®¡)
MALAYSIA_DEMOGRAPHICS = {
    "total_population": 33_200_000,
    "ethnic_distribution": {
        "Bumiputera": 0.697,
        "Chinese": 0.228,
        "Indian": 0.067,
        "Others": 0.008
    },
    "age_distribution": {
        "0-14": 0.234,
        "15-24": 0.166,
        "25-54": 0.433,
        "55-64": 0.094,
        "65+": 0.073
    },
    "urban_rural": {"urban": 0.779, "rural": 0.221},
    "states": {
        "Selangor": {"population": 6_900_000, "seats": 22},
        "Johor": {"population": 4_010_000, "seats": 26},
        "Sabah": {"population": 3_900_000, "seats": 25},
        "Sarawak": {"population": 2_820_000, "seats": 31},
        "Perak": {"population": 2_500_000, "seats": 24},
        "Kedah": {"population": 2_190_000, "seats": 15},
        "Penang": {"population": 1_770_000, "seats": 13},
        "Kelantan": {"population": 1_930_000, "seats": 14},
        "Pahang": {"population": 1_680_000, "seats": 14},
        "Terengganu": {"population": 1_270_000, "seats": 8},
        "N.Sembilan": {"population": 1_170_000, "seats": 8},
        "Melaka": {"population": 940_000, "seats": 6},
        "Perlis": {"population": 260_000, "seats": 3},
        "KL": {"population": 1_980_000, "seats": 11},
        "Putrajaya": {"population": 110_000, "seats": 1},
        "Labuan": {"population": 100_000, "seats": 1}
    }
}

# GE15 çœŸå®é€‰ä¸¾ç»“æœ (2022å¹´11æœˆ)
GE15_RESULTS = {
    "date": "2022-11-19",
    "coalitions": {
        "PH": {"seats": 82, "popular_vote_pct": 0.378, "parties": ["PKR", "DAP", "Amanah"]},
        "PN": {"seats": 73, "popular_vote_pct": 0.332, "parties": ["PAS", "Bersatu"]},
        "BN": {"seats": 30, "popular_vote_pct": 0.225, "parties": ["UMNO", "MCA", "MIC"]},
        "GPS": {"seats": 23, "popular_vote_pct": 0.041},
        "GRS": {"seats": 6, "popular_vote_pct": 0.015},
        "Others": {"seats": 8, "popular_vote_pct": 0.009}
    },
    "total_seats": 222,
    "turnout": 0.7387,
    "result": "Hung parliament â†’ Unity government (PH + BN + GPS + GRS)"
}

# GE14 (2018) for comparison
GE14_RESULTS = {
    "date": "2018-05-09",
    "coalitions": {
        "PH": {"seats": 113, "popular_vote_pct": 0.488},
        "BN": {"seats": 79, "popular_vote_pct": 0.337},
        "PAS": {"seats": 18, "popular_vote_pct": 0.168}
    },
    "turnout": 0.8221,
    "result": "PH won â†’ First change of government since independence"
}

def get_demographics() -> dict:
    return MALAYSIA_DEMOGRAPHICS

def get_election_history() -> dict:
    return {"ge15": GE15_RESULTS, "ge14": GE14_RESULTS}

def get_state_data(state: str) -> dict:
    return MALAYSIA_DEMOGRAPHICS["states"].get(state, {})
```

### O4: å‡çº§ Pipeline Stage 2
ä¿®æ”¹ `api/app/services/prediction_pipeline.py` çš„ Stage 2 (DataCollection):

```python
async def stage_2_data_collection(context: dict) -> dict:
    """æ”¶é›†çœŸå®æ•°æ® + LLMè¡¥å…¨"""
    from app.services.data_providers import worldbank, news, malaysia
    
    region = context.get("region", "MY")
    query = context["query"]
    
    # å¹¶è¡Œè·å–å¤šæºæ•°æ®
    import asyncio
    wb_gdp, wb_pop, wb_unemp, wb_inflation, news_data, my_demo = await asyncio.gather(
        worldbank.get_gdp(_region_to_code(region)),
        worldbank.get_population(_region_to_code(region)),
        worldbank.get_unemployment(_region_to_code(region)),
        worldbank.get_inflation(_region_to_code(region)),
        news.get_news_sentiment(query, _region_to_news_code(region)),
        asyncio.coroutine(lambda: malaysia.get_demographics())() if region == "MY" else asyncio.coroutine(lambda: {})(),
        return_exceptions=True
    )
    
    # å®¹é”™: ä»»ä½•æ•°æ®æºå¤±è´¥ä¸å½±å“æ•´ä½“
    economic_data = {}
    if not isinstance(wb_gdp, Exception): economic_data["gdp"] = wb_gdp
    if not isinstance(wb_unemp, Exception): economic_data["unemployment"] = wb_unemp
    if not isinstance(wb_inflation, Exception): economic_data["inflation"] = wb_inflation
    
    census_data = {}
    if not isinstance(wb_pop, Exception): census_data["population"] = wb_pop
    if not isinstance(my_demo, Exception) and my_demo: census_data["demographics"] = my_demo
    
    sentiment_data = news_data if not isinstance(news_data, Exception) else {}
    
    # LLM è¡¥å…¨ç¼ºå¤±æ•°æ®
    from app.core.llm import call_llm_json
    gap_fill = await call_llm_json("data_gap_fill", [{
        "role": "user",
        "content": f"""Based on available data and your knowledge, fill in missing context for: "{query}"

Available data:
- Economic: {json.dumps(economic_data, default=str)[:1000]}
- Census: {json.dumps(census_data, default=str)[:1000]}
- Sentiment: {json.dumps(sentiment_data, default=str)[:500]}

Identify what's missing and provide reasonable estimates.
Return JSON: {{
  "filled_gaps": [{{"field": "name", "value": "estimated value", "confidence": 0.0-1.0, "source": "llm_estimate"}}],
  "data_quality_assessment": "brief assessment",
  "overall_quality_score": 0.0-1.0
}}"""
    }])
    
    return {
        "economic": economic_data,
        "census": census_data,
        "sentiment": sentiment_data,
        "gap_fill": gap_fill,
        "sources": ["worldbank", "newsdata" if sentiment_data.get("source") != "llm_knowledge" else "llm", "dosm"],
        "quality_score": gap_fill.get("overall_quality_score", 0.5)
    }

def _region_to_code(region: str) -> str:
    mapping = {"MY": "MYS", "US": "USA", "CN": "CHN", "SG": "SGP", "ID": "IDN"}
    return mapping.get(region, region)

def _region_to_news_code(region: str) -> str:
    mapping = {"MY": "my", "US": "us", "CN": "cn", "SG": "sg"}
    return mapping.get(region, "my")
```

ä¸ºçœŸå®APIè°ƒç”¨å†™æµ‹è¯• (mock httpx):
- test_worldbank_api.py
- test_news_api.py
- test_malaysia_data.py
- test_stage2_real_data.py

### O5: ç¯å¢ƒå˜é‡æ›´æ–°
åœ¨ .env.example ä¸­æ–°å¢:
```
# å¯é€‰: æ–°é—»API (æ²¡æœ‰ä¹Ÿèƒ½è·‘ï¼Œç”¨LLM fallback)
NEWSDATA_API_KEY=
```

---

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PART II: æ€§èƒ½ä¼˜åŒ–
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## é˜¶æ®µ P: é€Ÿåº¦ + ç¼“å­˜ + å¹¶å‘

### P1: Redis ç¼“å­˜å±‚
åˆ›å»º `api/app/core/cache.py`:

```python
"""
Redisç¼“å­˜ â€” å‡å°‘é‡å¤LLMè°ƒç”¨å’Œæ•°æ®åº“æŸ¥è¯¢
"""
import redis.asyncio as redis
import json
import hashlib
import os

_redis = None

async def get_redis():
    global _redis
    if _redis is None:
        _redis = redis.from_url(os.environ.get("REDIS_URL", "redis://localhost:6379"))
    return _redis

async def cache_get(key: str):
    r = await get_redis()
    val = await r.get(key)
    return json.loads(val) if val else None

async def cache_set(key: str, value, ttl: int = 3600):
    r = await get_redis()
    await r.setex(key, ttl, json.dumps(value, default=str))

async def cache_delete(key: str):
    r = await get_redis()
    await r.delete(key)

def make_cache_key(prefix: str, *args) -> str:
    """ç”Ÿæˆç¼“å­˜key"""
    raw = f"{prefix}:" + ":".join(str(a) for a in args)
    return hashlib.md5(raw.encode()).hexdigest()
```

### P2: ç¼“å­˜ç­–ç•¥
åœ¨ä»¥ä¸‹åœ°æ–¹åŠ å…¥ç¼“å­˜:

1. **ä¸–ç•Œé“¶è¡Œæ•°æ®**: TTL=24å°æ—¶ (ç»æµæ•°æ®ä¸å¸¸å˜)
```python
async def get_gdp_cached(country_code):
    key = make_cache_key("wb_gdp", country_code)
    cached = await cache_get(key)
    if cached: return cached
    data = await get_gdp(country_code)
    await cache_set(key, data, ttl=86400)  # 24h
    return data
```

2. **æ–°é—»æ•°æ®**: TTL=1å°æ—¶
3. **trendingé¢„æµ‹åˆ—è¡¨**: TTL=5åˆ†é’Ÿ
4. **æ’è¡Œæ¦œ**: TTL=10åˆ†é’Ÿ
5. **ç”¨æˆ·profile**: TTL=30åˆ†é’Ÿ (æ›´æ–°æ—¶ä¸»åŠ¨æ¸…é™¤)

### P3: LLMè°ƒç”¨ä¼˜åŒ–
ä¿®æ”¹ `api/app/core/llm.py`:

```python
# 1. è¶…æ—¶æ§åˆ¶
async def call_llm(task, messages, timeout=60, **kwargs):
    import asyncio
    try:
        return await asyncio.wait_for(
            _raw_call(task, messages, **kwargs),
            timeout=timeout
        )
    except asyncio.TimeoutError:
        # é™çº§åˆ°æ›´å¿«çš„æ¨¡å‹é‡è¯•
        fallback_model = Models.HAIKU
        return await _raw_call_with_model(fallback_model, messages, **kwargs)

# 2. é‡è¯•æœºåˆ¶
async def _raw_call(task, messages, max_retries=2, **kwargs):
    for attempt in range(max_retries + 1):
        try:
            return await _do_call(task, messages, **kwargs)
        except Exception as e:
            if attempt == max_retries:
                raise
            await asyncio.sleep(1 * (attempt + 1))  # é€’å¢ç­‰å¾…

# 3. æˆæœ¬è¿½è¸ª
import time
_cost_log = []

async def _do_call(task, messages, **kwargs):
    model = TASK_MODEL.get(task, Models.HAIKU)
    start = time.time()
    resp = await client.chat.completions.create(model=model, messages=messages, **kwargs)
    elapsed = time.time() - start
    _cost_log.append({
        "task": task, "model": model, "elapsed": elapsed,
        "tokens_in": resp.usage.prompt_tokens if resp.usage else 0,
        "tokens_out": resp.usage.completion_tokens if resp.usage else 0,
    })
    return resp.choices[0].message.content
```

### P4: æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–
1. æ·»åŠ ç´¢å¼•:
```sql
-- supabase/migrations/006_indexes.sql
create index idx_predictions_user_id on public.predictions(user_id);
create index idx_predictions_status on public.predictions(status);
create index idx_predictions_public on public.predictions(is_public) where is_public = true;
create index idx_predictions_created on public.predictions(created_at desc);
create index idx_markets_status on public.markets(status);
create index idx_market_positions_market on public.market_positions(market_id);
create index idx_market_positions_user on public.market_positions(user_id);
create index idx_drift_events_type on public.drift_events(drift_type);
create index idx_drift_events_detected on public.drift_events(detected_at desc);
create index idx_studio_projects_user on public.studio_projects(user_id);
```

2. åˆ†é¡µ: æ‰€æœ‰åˆ—è¡¨APIç¡®ä¿æœ‰åˆ†é¡µ (page + page_size, é»˜è®¤20)

### P5: å‰ç«¯æ€§èƒ½
```bash
cd web
pnpm add @next/bundle-analyzer
```

1. **å›¾ç‰‡ä¼˜åŒ–**: æ‰€æœ‰å›¾ç‰‡ç”¨ next/image
2. **æ‡’åŠ è½½**: D3å› æœå›¾ã€PixiJS Agentã€Recharts éƒ½ç”¨ `dynamic(() => import(...), { ssr: false })`
3. **è™šæ‹Ÿæ»šåŠ¨**: Agentåˆ—è¡¨(å¯èƒ½1000+è¡Œ)ç”¨ react-window
4. **Prefetch**: ä»è¿›åº¦é¡µé¢„åŠ è½½ç»“æœé¡µç»„ä»¶
5. **Skeleton Loading**: æ‰€æœ‰æ•°æ®åŠ è½½é¡µç”¨ Skeleton å ä½

---

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PART III: å®‰å…¨åŠ å›º
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## é˜¶æ®µ Q: å®‰å…¨

### Q1: APIå®‰å…¨
åˆ›å»º `api/app/core/security.py`:

```python
"""å®‰å…¨ä¸­é—´ä»¶"""
from fastapi import Request, HTTPException
from starlette.middleware.base import BaseHTTPMiddleware
import time

# 1. Rate Limiting (ç®€å•ç‰ˆï¼Œç”Ÿäº§ç”¨Redis)
class RateLimitMiddleware(BaseHTTPMiddleware):
    def __init__(self, app, max_requests=100, window=60):
        super().__init__(app)
        self.max_requests = max_requests
        self.window = window
        self._requests = {}  # IP â†’ [(timestamp)]
    
    async def dispatch(self, request: Request, call_next):
        ip = request.client.host
        now = time.time()
        
        # æ¸…ç†è¿‡æœŸè®°å½•
        self._requests[ip] = [t for t in self._requests.get(ip, []) if now - t < self.window]
        
        if len(self._requests.get(ip, [])) >= self.max_requests:
            raise HTTPException(status_code=429, detail="Rate limit exceeded")
        
        self._requests.setdefault(ip, []).append(now)
        return await call_next(request)

# 2. CORS æ”¶ç´§
ALLOWED_ORIGINS = [
    "https://web-production-240e7.up.railway.app",
    "https://futureos.app",
    "http://localhost:3000",
]

# 3. è¾“å…¥æ¸…ç†
def sanitize_input(text: str, max_length: int = 1000) -> str:
    """é˜²æ­¢prompt injectionå’ŒXSS"""
    if not text: return ""
    text = text[:max_length]
    # ç§»é™¤å¯èƒ½çš„prompt injectionæ ‡è®°
    dangerous_patterns = ["<system>", "</system>", "<|", "|>", "ignore previous"]
    for pattern in dangerous_patterns:
        text = text.replace(pattern, "")
    return text.strip()
```

åœ¨ main.py ä¸­:
```python
app.add_middleware(RateLimitMiddleware, max_requests=60, window=60)
# æ”¶ç´§CORS
app.add_middleware(CORSMiddleware, allow_origins=ALLOWED_ORIGINS, ...)
```

### Q2: è¾“å…¥éªŒè¯åŠ å›º
æ£€æŸ¥æ‰€æœ‰ Pydantic schema:
- queryå­—æ®µæœ€å¤§1000å­—ç¬¦
- æ‰€æœ‰IDå­—æ®µç”¨UUIDéªŒè¯
- é‡‘é¢å­—æ®µè®¾ç½®æœ€å¤§å€¼(10000ç§¯åˆ†)
- æ–‡ä»¶ä¸Šä¼ é™åˆ¶å¤§å°(10MB)

### Q3: ç¯å¢ƒå˜é‡å®‰å…¨
- ç¡®ä¿ .env åœ¨ .gitignore ä¸­
- Railwayç¯å¢ƒå˜é‡ä¸æš´éœ²åˆ°å‰ç«¯
- SUPABASE_SERVICE_ROLE_KEY åªåœ¨åç«¯ä½¿ç”¨
- å‰ç«¯åªæœ‰ NEXT_PUBLIC_ å¼€å¤´çš„å˜é‡

---

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PART IV: SEO + å›½é™…åŒ– + UIæ‰“ç£¨
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## é˜¶æ®µ R: ä¸Šçº¿æ‰“ç£¨

### R1: SEO
ä¿®æ”¹ `src/app/layout.tsx`:
```typescript
export const metadata: Metadata = {
  title: "FutureOS â€” AIé¢„æµ‹å¼•æ“ | æ¢ç´¢ä»»ä½•é—®é¢˜çš„æœªæ¥",
  description: "åŸºäºå¤šAgentä»¿çœŸå’Œä¸‰å¼•æ“æ¨ç†çš„AIé¢„æµ‹å¹³å°ã€‚å› æœå›¾å¯è§†åŒ–ï¼Œå®æ—¶å˜é‡æ“æ§ï¼Œä¸“ä¸šçº§åˆ†æã€‚",
  keywords: ["AIé¢„æµ‹", "å› æœæ¨ç†", "é¢„æµ‹å¸‚åœº", "Agentä»¿çœŸ", "FutureOS"],
  openGraph: {
    title: "FutureOS â€” AIé¢„æµ‹å¼•æ“",
    description: "æ¢ç´¢ä»»ä½•é—®é¢˜çš„æœªæ¥",
    url: "https://futureos.app",
    siteName: "FutureOS",
    images: [{ url: "/og-image.png", width: 1200, height: 630 }],
    locale: "zh_CN",
    type: "website",
  },
  twitter: {
    card: "summary_large_image",
    title: "FutureOS â€” AIé¢„æµ‹å¼•æ“",
    description: "æ¢ç´¢ä»»ä½•é—®é¢˜çš„æœªæ¥",
  },
  robots: { index: true, follow: true },
};
```

æ¯ä¸ªä¸»è¦é¡µé¢éƒ½åŠ  generateMetadata:
- /lite: "Lite â€” å¿«é€ŸAIé¢„æµ‹"
- /studio: "Studio â€” ä¸“ä¸šé¢„æµ‹å·¥ä½œå°"
- /exchange: "Exchange â€” é¢„æµ‹å¸‚åœº"
- /lite/[id]/result: åŠ¨æ€æ ‡é¢˜ "é¢„æµ‹: {query}"

### R2: OG Image
åˆ›å»º `public/og-image.png`:
- ç”¨ä»£ç ç”Ÿæˆ: 1200Ã—630 æ·±è‰²èƒŒæ™¯ + Logo + Tagline
- æˆ–è€…åˆ›å»º `src/app/api/og/route.tsx` ç”¨ @vercel/og åŠ¨æ€ç”Ÿæˆ

### R3: å›½é™…åŒ–åŸºç¡€
ä¸åšå®Œæ•´i18nï¼Œä½†ç¡®ä¿:
- æ‰€æœ‰UIæ–‡å­—ç»Ÿä¸€ (ä¸è¦ä¸­è‹±æ··æ‚)
- ä¸»è¦é€‰æ‹©ä¸­æ–‡ UI + è‹±æ–‡æŠ€æœ¯æœ¯è¯­
- LLM promptç»Ÿä¸€ç”¨è‹±æ–‡ (æ•ˆæœæ›´å¥½)
- ç”¨æˆ·è¾“å…¥æ”¯æŒä¸­è‹±æ–‡

### R4: UIæè‡´æ‰“ç£¨
é€é¡µæ£€æŸ¥å¹¶ä¿®å¤:

**å…¨å±€:**
- æ·±è‰²ä¸»é¢˜ä¸€è‡´æ€§ (æ‰€æœ‰é¡µé¢ç»Ÿä¸€é…è‰²)
- åŠ è½½çŠ¶æ€: æ¯ä¸ªæ•°æ®åŠ è½½éƒ½æœ‰Skeleton
- ç©ºçŠ¶æ€: æ¯ä¸ªåˆ—è¡¨ç©ºæ—¶æœ‰å‹å¥½æç¤º + å¼•å¯¼æ“ä½œ
- é”™è¯¯çŠ¶æ€: ç»Ÿä¸€é”™è¯¯é¡µé¢/toast
- è¿‡æ¸¡åŠ¨ç”»: é¡µé¢åˆ‡æ¢æœ‰fade transition
- Favicon: åˆ›å»ºfavicon.ico + apple-touch-icon

**Landing Page:**
- HeroåŠ¨ç”»: å¾®å¦™çš„ç²’å­/ç½‘æ ¼èƒŒæ™¯åŠ¨ç”» (ç”¨CSS, ä¸ç”¨heavyåº“)
- ç¤¾ä¼šè¯æ˜: çœŸå®æ•°æ® "å·²æœ‰Xä¸ªé¢„æµ‹" "å¹³å‡å‡†ç¡®åº¦Y%"
- åŠ è½½é€Ÿåº¦: Lighthouse Performance > 90

**Liteç»“æœé¡µ:**
- å› æœå›¾: åˆå§‹åŠ è½½åŠ¨ç”» (èŠ‚ç‚¹é€ä¸ªå‡ºç°)
- å˜é‡æ»‘å—: æ‹–åŠ¨æ—¶æœ‰å®æ—¶æ•°å­—åé¦ˆ
- æ¦‚ç‡å˜åŒ–: æ•°å­—è·³åŠ¨åŠ¨ç”» (countup effect)

**Studio:**
- React Flow: èŠ‚ç‚¹æ ·å¼ç¾åŒ– (åœ†è§’ã€é˜´å½±ã€é¢œè‰²ç¼–ç )
- ä»ªè¡¨ç›˜: æ•°å­—ç”¨å¤§å­—ä½“çªå‡º

### R5: é”™è¯¯è¾¹ç•Œ
åˆ›å»º `src/components/error-boundary.tsx`:
- React Error Boundary åŒ…è£¹æ¯ä¸ªä¸»è¦åŒºå—
- æŠ¥é”™æ—¶æ˜¾ç¤ºå‹å¥½ç•Œé¢ + "é‡è¯•" æŒ‰é’®
- ä¸å½±å“å…¶ä»–åŒºå—

### R6: 404é¡µé¢
åˆ›å»º `src/app/not-found.tsx`:
- å‹å¥½çš„404é¡µé¢
- æœç´¢æ¡† + è¿”å›é¦–é¡µæŒ‰é’®

---

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PART V: ç›‘æ§ + æ—¥å¿—
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## é˜¶æ®µ S: å¯è§‚æµ‹æ€§

### S1: Sentryé”™è¯¯ç›‘æ§
åç«¯:
```bash
cd api && poetry add sentry-sdk[fastapi]
```
```python
# api/app/main.py
import sentry_sdk
sentry_sdk.init(dsn=os.environ.get("SENTRY_DSN", ""), traces_sample_rate=0.1)
```

å‰ç«¯:
```bash
cd web && pnpm add @sentry/nextjs
```
```javascript
// sentry.client.config.ts
Sentry.init({ dsn: process.env.NEXT_PUBLIC_SENTRY_DSN, tracesSampleRate: 0.1 });
```

### S2: å¥åº·æ£€æŸ¥å¢å¼º
ä¿®æ”¹ `GET /api/v1/health`:
```json
{
  "status": "healthy",
  "version": "1.5.0",
  "services": {
    "database": "connected",
    "redis": "connected",
    "openrouter": "reachable"
  },
  "uptime_seconds": 12345,
  "last_prediction_at": "2026-02-07T..."
}
```

### S3: APIæ—¥å¿—
æ¯ä¸ªAPIè¯·æ±‚è®°å½•:
- è·¯å¾„ + æ–¹æ³• + çŠ¶æ€ç  + è€—æ—¶
- LLMè°ƒç”¨: task + model + tokens + è€—æ—¶ + æˆæœ¬
- å†™å…¥audit_logsè¡¨

### S4: æˆæœ¬ä»ªè¡¨ç›˜ API
```
GET /api/v1/admin/costs â†’ {
  "today": {"total_usd": 1.23, "calls": 45, "by_model": {...}},
  "this_week": {...},
  "this_month": {...}
}
```

ä»LLMè°ƒç”¨æ—¥å¿—ä¸­èšåˆã€‚å¸®åŠ©ä½ ç›‘æ§OpenRouterèŠ±è´¹ã€‚

---

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PART VI: éƒ¨ç½²ä¼˜åŒ–
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## é˜¶æ®µ T: Railwayç”Ÿäº§é…ç½®

### T1: Dockerfileä¼˜åŒ–
ç¡®ä¿ `api/Dockerfile` å¤šé˜¶æ®µæ„å»º:
```dockerfile
FROM python:3.12-slim AS builder
WORKDIR /app
COPY pyproject.toml poetry.lock ./
RUN pip install poetry && poetry export -f requirements.txt > requirements.txt

FROM python:3.12-slim
WORKDIR /app
COPY --from=builder /app/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "2"]
```

### T2: Railway Serviceé…ç½®
æ¯ä¸ªServiceç¡®ä¿:
- web: `pnpm build && pnpm start`
- api: Dockerfileéƒ¨ç½², 2 workers
- worker: åŒDockerfile, CMDæ”¹ä¸ºCelery worker
- Redis: Railwayæ’ä»¶, æŒä¹…åŒ–å¼€å¯
- å¥åº·æ£€æŸ¥è·¯å¾„é…ç½®

### T3: è‡ªå®šä¹‰åŸŸåå‡†å¤‡
å¦‚æœæœ‰åŸŸå futureos.app:
- Railwayè‡ªå®šä¹‰åŸŸåé…ç½®
- SSLè‡ªåŠ¨(Railwayå¤„ç†)
- å‰ç«¯ NEXT_PUBLIC_API_URL æŒ‡å‘APIåŸŸå

---

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PART VII: æœ€ç»ˆéªŒè¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## é˜¶æ®µ U: Production Checklist

### U1: è¿è¡Œå…¨éƒ¨æµ‹è¯•
```bash
cd api && pytest -v --cov=app --tb=short
cd web && pnpm test
cd web && npx playwright test
cd web && pnpm build
```
å…¨éƒ¨å¿…é¡»é€šè¿‡ï¼Œä¸èƒ½æœ‰å›å½’ã€‚

### U2: Lighthouseå®¡è®¡
ç”¨ Playwright æˆ–æ‰‹åŠ¨è·‘ Lighthouse:
- / (Landing): Performance > 85, Accessibility > 90, SEO > 90
- /lite: Performance > 80
- /lite/[id]/result: Performance > 70 (D3é‡ï¼Œå¯æ¥å—)

### U3: çœŸå®æ•°æ®éªŒè¯
1. è¾“å…¥"2026é©¬æ¥è¥¿äºšå¤§é€‰è°èµ¢" â†’ æ£€æŸ¥Stage 2æ˜¯å¦æ‹‰åˆ°ä¸–ç•Œé“¶è¡ŒçœŸå®GDPæ•°æ®
2. æ£€æŸ¥å› æœå›¾çš„æ•°æ®æ˜¯å¦æ¯”ä¹‹å‰mockæ›´ä¸°å¯Œ
3. æ£€æŸ¥æ–°é—»æƒ…æ„Ÿåˆ†ææ˜¯å¦æœ‰å†…å®¹

### U4: å®‰å…¨æ‰«æ
- ç¡®è®¤ .env ä¸åœ¨gitä¸­
- ç¡®è®¤å‰ç«¯æ— æ•æ„Ÿkeyæ³„éœ²
- ç¡®è®¤CORSåªå…è®¸æŒ‡å®šåŸŸå
- ç¡®è®¤Rate Limitå·¥ä½œ

---

## å®Œæˆæ ‡å‡†

```
=== çœŸå®æ•°æ® ===
[ ] ä¸–ç•Œé“¶è¡ŒAPI: GDP/äººå£/å¤±ä¸š/é€šèƒ€æ•°æ®å¯è·å–
[ ] æ–°é—»API: æœ‰fallback(æ— keyç”¨LLM)
[ ] é©¬æ¥è¥¿äºšæ•°æ®: çœŸå®äººå£/é€‰ä¸¾æ•°æ®
[ ] Pipeline Stage 2ä½¿ç”¨çœŸå®æ•°æ®
[ ] æ•°æ®è·å–å¤±è´¥ä¸å½±å“æ•´ä½“æµç¨‹

=== æ€§èƒ½ ===
[ ] Redisç¼“å­˜å±‚å·¥ä½œ
[ ] ä¸–ç•Œé“¶è¡Œæ•°æ®ç¼“å­˜24h
[ ] Trendingåˆ—è¡¨ç¼“å­˜5min
[ ] LLMè¶…æ—¶â†’é™çº§åˆ°Haiku
[ ] LLMé‡è¯•æœºåˆ¶
[ ] æ•°æ®åº“ç´¢å¼•å·²åˆ›å»º
[ ] æ‰€æœ‰åˆ—è¡¨APIæœ‰åˆ†é¡µ
[ ] å‰ç«¯æ‡’åŠ è½½(D3/PixiJS/Recharts)
[ ] Skeleton Loading

=== å®‰å…¨ ===
[ ] Rate Limiting (60/min)
[ ] CORSæ”¶ç´§
[ ] è¾“å…¥æ¸…ç†(é˜²prompt injection)
[ ] Pydantic schemaæœ‰é•¿åº¦é™åˆ¶
[ ] .envåœ¨.gitignoreä¸­
[ ] å‰ç«¯æ— æ•æ„Ÿkey

=== SEO + UI ===
[ ] å…¨å±€meta tags
[ ] OG Image
[ ] æ¯é¡µæœ‰generateMetadata
[ ] Favicon
[ ] 404é¡µé¢
[ ] Error Boundary
[ ] æ·±è‰²ä¸»é¢˜ä¸€è‡´
[ ] Skeleton Loadingå…¨è¦†ç›–
[ ] ç©ºçŠ¶æ€å‹å¥½æç¤º

=== ç›‘æ§ ===
[ ] Sentryåç«¯æ¥å…¥
[ ] Sentryå‰ç«¯æ¥å…¥
[ ] å¥åº·æ£€æŸ¥å¢å¼º
[ ] APIè¯·æ±‚æ—¥å¿—
[ ] LLMæˆæœ¬è¿½è¸ª

=== éƒ¨ç½² ===
[ ] Dockerfileå¤šé˜¶æ®µæ„å»º
[ ] Railwayé…ç½®ä¼˜åŒ–
[ ] æ‰€æœ‰æµ‹è¯•é€šè¿‡(æ— å›å½’)
[ ] pnpm buildæ— é”™è¯¯

=== çœŸå®æµç¨‹éªŒè¯ ===
[ ] è¾“å…¥é—®é¢˜â†’çœŸå®æ•°æ®â†’ä¸‰å¼•æ“â†’å› æœå›¾â†’å˜é‡â†’æ¦‚ç‡å˜åŒ– å…¨æµç¨‹
[ ] Studioå…¨æµç¨‹: æ•°æ®â†’äººå£â†’æƒ…æ™¯â†’ä»¿çœŸâ†’æŠ¥å‘Šâ†’PDF
[ ] Exchange: å¸‚åœºâ†’ä¸‰ä¿¡å·â†’ä¸‹æ³¨
[ ] æ¼‚ç§»ä»ªè¡¨ç›˜æœ‰æ•°æ®
```

å¼€å§‹ã€‚æŒ‰ Oâ†’Pâ†’Qâ†’Râ†’Sâ†’Tâ†’U é¡ºåºã€‚è‡ªä¸»å†³ç­–ï¼Œå®Œæˆåæ±‡æŠ¥ã€‚
